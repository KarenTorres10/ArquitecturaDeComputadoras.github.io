<!DOCTYPE html>
<html>

	<head>
		<meta charset="utf-8">
		<title>
			computacion paralela
		</title>
	</head>
	<body>
		<div style ="background-image:url('imagenes/fondo2.jpg');
			position:fixed; top:0; bottom:0; right:0; left:0;
			background-repeat:no-repeat;
			background-size:cover; 
			background-attachment:fixed;
			z-index:-1"> 
			</div>
			<p style="text-align:justify; font-style:Bold; color: white;">
			 Paralelismo a nivel de bit
Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la 
década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida 
duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo.

Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta 
tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que ha sido un estándar en la computación 
de propósito general durante la última década.

Paralelismo a nivel de instrucción
Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una 
acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un pipeline de N 
etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización.

Paralelismo de datos
El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos 
entre los diferentes nodos computacionales que deben tratarse en paralelo. Muchas de las aplicaciones científicas y de 
ingeniería muestran paralelismo de datos.
			<img src="imagenes/Paralelo.png" 
		style="height:300px; width:300px;">
		</a>
<p style="text-align:justify; font-style:Bold; color: white;">
	Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más 
	iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos.

Paralelismo de tareas
Es un paradigma de la programación concurrente que consiste en asignar distintas tareas a cada uno de los procesadores de un 
sistema de cómputo. En consecuencia, cada procesador efectuará su propia secuencia de operaciones. En su modo más general, el 
paralelismo de tareas se representa mediante un grafo de tareas, el cual es subdividido en subgrafos que son luego asignados a 
diferentes procesadores.
			</p>
	</body>

</html>
